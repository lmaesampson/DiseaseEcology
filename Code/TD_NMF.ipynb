{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Lars Buitinck\n",
    "#         Chyi-Kwei Yau <chyikwei.yau@gmail.com>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "n_features = 1000\n",
    "n_topics = 15\n",
    "n_top_words = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfilenames = open('../Papers/15/pdflist.txt').read().splitlines()\\nfor f in filenames:\\n    print(f)\\n    !pdftotext ../Papers/15/$f \\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build the corpus (This cell only needed to be called once to make the .txt files)\n",
    "'''\n",
    "filenames = open('../Papers/15/pdflist.txt').read().splitlines()\n",
    "for f in filenames:\n",
    "    print(f)\n",
    "    !pdftotext ../Papers/15/$f \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330\n"
     ]
    }
   ],
   "source": [
    "# Strip common English words, words occurring in\n",
    "# only one document or in at least 95%, as well as a list of other words\n",
    "t0 = time()\n",
    "docslist = []\n",
    "filenames = open('../Papers/15/textlist.txt').read().splitlines()\n",
    "for f in filenames:\n",
    "    txtfile = open('../Papers/15/'+f).read()\n",
    "    docslist.append(txtfile)\n",
    "filenames = open('../Papers/05/textlist.txt').read().splitlines()\n",
    "for f in filenames:\n",
    "    txtfile = open('../Papers/05/'+f).read()\n",
    "    docslist.append(txtfile)\n",
    "filenames = open('../Papers/00/textlist.txt').read().splitlines()\n",
    "for f in filenames:\n",
    "    txtfile = open('../Papers/00/'+f).read()\n",
    "    docslist.append(txtfile)\n",
    "filenames = open('../Papers/95/textlist.txt').read().splitlines()\n",
    "for f in filenames:\n",
    "    txtfile = open('../Papers/95/'+f).read()\n",
    "    docslist.append(txtfile)\n",
    "filenames = open('../Papers/90/textlist.txt').read().splitlines()\n",
    "for f in filenames:\n",
    "    txtfile = open('../Papers/90/'+f).read()\n",
    "    docslist.append(txtfile)\n",
    "filenames = open('../Papers/79-82/textlist.txt').read().splitlines()\n",
    "for f in filenames:\n",
    "    txtfile = open('../Papers/79-82/'+f).read()\n",
    "    docslist.append(txtfile)\n",
    "\n",
    "print(len(docslist))\n",
    "dataset = docslist\n",
    "data_samples = dataset\n",
    "\n",
    "sw = list(stopwords.words('english'))\n",
    "ignore_words = ['annual','review','journal','may','anderson','reviews','ann','rev','rights','reserved','institution',\n",
    "               'annu','fig','b','equation','equations','biological','biology','a','b','c','d','e','f','g','h','i','j',\\\n",
    "               'k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','use', 'uses','year','figure','studied','per',\\\n",
    "               'see','however','new','utc','http','https','et','al','one','two','study','studying','studies', 'also','used',\\\n",
    "               'thus','\\u03c3','\\u03c9','aug','thu','would','many','found','downloaded','press','university','within','de',\\\n",
    "               'could','should','results','result','effect','effects','total','given','using','table','likely','therefore',\\\n",
    "               'however','important','pp','among','ro','since','significant','first','\\uxe4','must','well','levin','section',\\\n",
    "               'much','particular','second','first','show','based','part','biol','either','society','2001','2002','2003',\n",
    "               '1999','2000','2018','org','jstor','10','165','daszak','di','1998','eids','nh','ctl','www','com','main,'\\\n",
    "               '1','2','3','4','5','130','17','203','75','18','cambridge','press','pdf','2006','1996','2005','contents',\\\n",
    "               '1979','1982','164','09','02','76','1990','200','08','48','58','42','41','27','21','23','1017','31','16',\\\n",
    "               '36','46','35','vol','pg','1981','1985','1988','47','1980','oxford',\n",
    "               '2012','2011','2010','2009','2008','2007','2006','2005','2004','2003','2002','2001','2000','1979','1980',\\\n",
    "               '1981','1982','1983','1984','1985','1986','1987','1988','1989','1990','1991','1992','1993','1994','1995',\\\n",
    "               '1978','1996','1997','1998','1999']\n",
    "sw_all = sw+ignore_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "done in 2.612s.\n",
      "Fitting the NMF model with tf-idf features,\n",
      "done in 0.379s.\n",
      "\n",
      "Topics in NMF model:\n",
      "Topic #0:\n",
      "parasite host parasites hosts infection population species density infected core parasitology daphnia fecundity growth life\n",
      "Topic #1:\n",
      "equilibrium model population r0 models disease rate dt theorem endemic math time stable system epidemic\n",
      "Topic #2:\n",
      "disease population species infection populations diseases wildlife human animals health infectious transmission host pathogen control\n",
      "Topic #3:\n",
      "s2 main class six five four three energy ds differential eq co adult 13 stochastic\n",
      "Topic #4:\n",
      "virulence strain transmission evolution strains virulent hosts host vertical rate pathogen infected horizontal mortality optimal\n",
      "Topic #5:\n",
      "larvae transmission density larval virus infected densities insect experiment host rate pathogen action dynamics hosts\n",
      "Topic #6:\n",
      "virus viruses viral rabbits rabbit cells cell strains host gene strain human hiv load immune\n",
      "Topic #7:\n",
      "plant plants seed diseased leaf host pathogen disease pathogens vector spore healthy leaves spores species\n",
      "Topic #8:\n",
      "content subject terms naturalist american dynamics food stable pages interactions insect insects prey pathogen source\n",
      "Topic #9:\n",
      "network doi social networks 2013 royalsocietypublishing 2014 rspb 1016 2015 time soc data health contact\n",
      "Topic #10:\n",
      "males females female male flies parasites birds sexual mites parasitism sex energy parasitized infected intensity\n",
      "Topic #11:\n",
      "bats colony species 2015 north colonies america white 2014 intensity conservation brown 2013 rspb pathogen\n",
      "Topic #12:\n",
      "fish salmon sea lake mortality parasites marine intensity size length resistance correlation sample class mean\n",
      "Topic #13:\n",
      "possums possum tb zealand bovis tuberculosis bovine control disease prevalence veterinary cattle wildlife forest infection\n",
      "Topic #14:\n",
      "group nature groups selection authors probability helminth social article size 2015 june 74 source process\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.98, min_df=5,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words=sw_all)\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model with tf-idf features,\")\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_topics, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model:\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
